#!/usr/bin/env python

import os
import requests
import re
import jieba
import json
from datetime import datetime
from collections import Counter, defaultdict
from typing import List, Set, Dict, Tuple
from difflib import SequenceMatcher

API_KEY = os.getenv("DEEPSEEK_API_KEY")
API_URL = "https://api.deepseek.com/v1/chat/completions"

class TitleAnalyzer:
    """æ™ºèƒ½æ ‡é¢˜åˆ†æå™¨"""

    def __init__(self):
        # å¸¸è§çš„é‡å¤æ¨¡å¼æ­£åˆ™è¡¨è¾¾å¼
        self.repetitive_patterns = [
            r'^ä¼š.+çš„.+$',           # ä¼š...çš„...
            r'^.+çš„.+å£°$',           # Xçš„Xå£°
            r'^.+çš„.+å…‰$',           # Xçš„Xå…‰
            r'^.+çš„.+å¤œ$',           # Xçš„Xå¤œ
            r'^.+çš„.+æ¢¦$',           # Xçš„Xæ¢¦
            r'^.+çš„.+æ­Œ$',           # Xçš„Xæ­Œ
            r'^.+é‡Œçš„.+$',           # Xé‡Œçš„X
            r'^.+ä¸­çš„.+$',           # Xä¸­çš„X
            r'^æœ€åçš„.+$',           # æœ€åçš„X
            r'^æ¶ˆå¤±çš„.+$',           # æ¶ˆå¤±çš„X
            r'^ç¥ç§˜çš„.+$',           # ç¥ç§˜çš„X
        ]

        # è¿‡åº¦ä½¿ç”¨çš„è¯æ±‡
        self.overused_words = {
            'ä¼š', 'çš„', 'æ¶ˆå¤±', 'ç¥ç§˜', 'æœ€å', 'å¤è€', 'å¥‡æ€ª', 'é­”æ³•',
            'å£°éŸ³', 'å¤œæ™š', 'æ¢¦å¢ƒ', 'è®°å¿†', 'æ•…äº‹', 'ç§˜å¯†', 'æ—¶é—´'
        }

        # æ ‡é¢˜è´¨é‡æƒé‡
        self.quality_weights = {
            'length': 0.2,      # é•¿åº¦é€‚ä¸­
            'uniqueness': 0.3,  # ç‹¬ç‰¹æ€§
            'poetry': 0.2,      # è¯—æ„æ€§
            'specificity': 0.3  # å…·ä½“æ€§
        }

    def extract_keywords(self, title: str) -> Set[str]:
        """æå–æ ‡é¢˜å…³é”®è¯"""
        # ä½¿ç”¨jiebaåˆ†è¯
        words = jieba.lcut(title)
        # è¿‡æ»¤åœç”¨è¯å’Œå•å­—ç¬¦
        keywords = {word for word in words if len(word) > 1 and word not in {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æœ‰'}}
        return keywords

    def calculate_similarity(self, title1: str, title2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ ‡é¢˜çš„ç›¸ä¼¼åº¦"""
        # å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
        string_sim = SequenceMatcher(None, title1, title2).ratio()

        # å…³é”®è¯ç›¸ä¼¼åº¦
        keywords1 = self.extract_keywords(title1)
        keywords2 = self.extract_keywords(title2)

        if not keywords1 or not keywords2:
            keyword_sim = 0
        else:
            intersection = len(keywords1 & keywords2)
            union = len(keywords1 | keywords2)
            keyword_sim = intersection / union if union > 0 else 0

        # ç»“æ„ç›¸ä¼¼åº¦ï¼ˆé•¿åº¦æ¯”è¾ƒï¼‰
        len_sim = 1 - abs(len(title1) - len(title2)) / max(len(title1), len(title2))

        # ç»¼åˆç›¸ä¼¼åº¦
        return 0.4 * string_sim + 0.4 * keyword_sim + 0.2 * len_sim

    def is_repetitive_pattern(self, title: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤æ¨¡å¼"""
        for pattern in self.repetitive_patterns:
            if re.match(pattern, title):
                return True
        return False

    def calculate_title_quality(self, title: str, existing_titles: List[str]) -> float:
        """è®¡ç®—æ ‡é¢˜è´¨é‡åˆ†æ•° (0-1)"""
        score = 0

        # é•¿åº¦è¯„åˆ† (4-8ä¸ªå­—ç¬¦ä¸ºæœ€ä½³)
        length_score = 1 - abs(len(title) - 6) / 10
        length_score = max(0, min(1, length_score))

        # ç‹¬ç‰¹æ€§è¯„åˆ† (ä¸ç°æœ‰æ ‡é¢˜çš„å¹³å‡ç›¸ä¼¼åº¦)
        if existing_titles:
            similarities = [self.calculate_similarity(title, existing) for existing in existing_titles[-50:]]
            uniqueness_score = 1 - max(similarities) if similarities else 1
        else:
            uniqueness_score = 1

        # è¯—æ„æ€§è¯„åˆ† (é¿å…è¿‡åº¦ä½¿ç”¨çš„è¯æ±‡)
        overused_count = sum(1 for word in self.overused_words if word in title)
        poetry_score = max(0, 1 - overused_count * 0.2)

        # å…·ä½“æ€§è¯„åˆ† (é¿å…è¿‡äºæŠ½è±¡çš„è¯æ±‡)
        abstract_words = {'ä¸œè¥¿', 'äº‹æƒ…', 'åœ°æ–¹', 'æ—¶å€™', 'æ ·å­', 'æ„Ÿè§‰'}
        abstract_count = sum(1 for word in abstract_words if word in title)
        specificity_score = max(0, 1 - abstract_count * 0.3)

        # ç»¼åˆè¯„åˆ†
        score = (
            self.quality_weights['length'] * length_score +
            self.quality_weights['uniqueness'] * uniqueness_score +
            self.quality_weights['poetry'] * poetry_score +
            self.quality_weights['specificity'] * specificity_score
        )

        return score

    def is_title_acceptable(self, title: str, existing_titles: List[str], min_quality: float = 0.6) -> Tuple[bool, str]:
        """åˆ¤æ–­æ ‡é¢˜æ˜¯å¦å¯æ¥å—"""
        # æ£€æŸ¥é‡å¤æ¨¡å¼
        if self.is_repetitive_pattern(title):
            return False, f"ä½¿ç”¨äº†é‡å¤æ¨¡å¼: {title}"

        # æ£€æŸ¥å®Œå…¨é‡å¤
        if title in existing_titles:
            return False, f"æ ‡é¢˜å·²å­˜åœ¨: {title}"

        # æ£€æŸ¥é«˜ç›¸ä¼¼åº¦
        for existing in existing_titles[-30:]:  # æ£€æŸ¥æœ€è¿‘30ä¸ª
            if self.calculate_similarity(title, existing) > 0.7:
                return False, f"ä¸ç°æœ‰æ ‡é¢˜è¿‡äºç›¸ä¼¼: {existing}"

        # æ£€æŸ¥è´¨é‡
        quality = self.calculate_title_quality(title, existing_titles)
        if quality < min_quality:
            return False, f"æ ‡é¢˜è´¨é‡ä¸è¾¾æ ‡: {quality:.2f} < {min_quality}"

        return True, f"è´¨é‡è¯„åˆ†: {quality:.2f}"


class SmartStoryGenerator:
    """æ™ºèƒ½æ•…äº‹ç”Ÿæˆå™¨"""

    def __init__(self):
        self.analyzer = TitleAnalyzer()
        self.generation_history = []  # è®°å½•ç”Ÿæˆå†å²

    def load_existing_titles(self) -> List[str]:
        """åŠ è½½ç°æœ‰æ ‡é¢˜"""
        files = [x for x in os.listdir("_posts") if x.endswith(".md")]
        files.sort()
        return [x.split("-")[3].split(".")[0] for x in files]

    def analyze_title_trends(self, titles: List[str]) -> Dict:
        """åˆ†ææ ‡é¢˜è¶‹åŠ¿"""
        # åˆ†æå¸¸è§æ¨¡å¼
        patterns = []
        for title in titles:
            for pattern in self.analyzer.repetitive_patterns:
                if re.match(pattern, title):
                    patterns.append(pattern)

        pattern_counts = Counter(patterns)

        # åˆ†æå¸¸ç”¨è¯æ±‡
        all_keywords = []
        for title in titles:
            all_keywords.extend(self.analyzer.extract_keywords(title))

        word_counts = Counter(all_keywords)

        return {
            'total_titles': len(titles),
            'common_patterns': dict(pattern_counts.most_common(5)),
            'overused_words': dict(word_counts.most_common(10)),
            'avg_length': sum(len(title) for title in titles) / len(titles) if titles else 0
        }

    def generate_enhanced_prompt(self, existing_titles: List[str], attempt: int = 1) -> str:
        """ç”Ÿæˆå¢å¼ºçš„æç¤ºè¯"""
        trends = self.analyze_title_trends(existing_titles)
        recent_titles = existing_titles[-20:] if len(existing_titles) > 20 else existing_titles

        # æ ¹æ®å°è¯•æ¬¡æ•°è°ƒæ•´ä¸¥æ ¼ç¨‹åº¦
        strictness_levels = [
            "è¯·æ³¨æ„",
            "ç‰¹åˆ«å¼ºè°ƒï¼Œä¸¥æ ¼",
            "æœ€åè­¦å‘Šï¼Œç»å¯¹"
        ]
        strictness = strictness_levels[min(attempt - 1, len(strictness_levels) - 1)]

        prompt = f"""è¯·åˆ›ä½œä¸€ä¸ª800å­—å·¦å³çš„é­”å¹»ç°å®ä¸»ä¹‰çŸ­ç¯‡æ•…äº‹ã€‚

{strictness}è¦æ±‚ï¼š

1. æ ‡é¢˜è¦æ±‚ï¼ˆæå…¶é‡è¦ï¼‰ï¼š
   - ç»å¯¹ä¸è¦ä½¿ç”¨ä»¥ä¸‹é‡å¤æ¨¡å¼ï¼š{', '.join(trends['common_patterns'].keys())}
   - é¿å…è¿‡åº¦ä½¿ç”¨è¯æ±‡ï¼š{', '.join(list(trends['overused_words'].keys())[:5])}
   - æ ‡é¢˜é•¿åº¦å»ºè®®ï¼š4-8ä¸ªæ±‰å­—
   - å¿…é¡»å…·ä½“ã€ç‹¬ç‰¹ã€æœ‰è¯—æ„
   - å¯å‚è€ƒé£æ ¼ï¼šã€Šåˆå¤œç†å‘åº—ã€‹ã€ŠçŸ³æ¡¥ä¸Šçš„é‚®å·®ã€‹ã€Šé˜¿å©†çš„é’ˆçº¿ç›’ã€‹

2. ä¸¥æ ¼ç¦æ­¢çš„æ ‡é¢˜ç±»å‹ï¼š
   - "ä¼š...çš„..." æ ¼å¼
   - "...çš„å£°éŸ³/å…‰/æ¢¦/å¤œ" æ ¼å¼
   - "æ¶ˆå¤±çš„..." "ç¥ç§˜çš„..." "æœ€åçš„..." æ ¼å¼
   - è¿‡äºæŠ½è±¡æˆ–å¸¸è§çš„è¯æ±‡

3. ä¸è¦ä½¿ç”¨è¿™äº›å·²æœ‰æ ‡é¢˜ï¼š{', '.join(recent_titles[-10:])}

4. æ•…äº‹å†…å®¹ï¼šä½“ç°é­”å¹»ç°å®ä¸»ä¹‰ï¼Œèåˆè¶…ç°å®ä¸æ—¥å¸¸ç”Ÿæ´»

ç¬¬{attempt}æ¬¡å°è¯• - è¯·ç¡®ä¿æ ‡é¢˜å®Œå…¨åŸåˆ›ä¸”å¯Œæœ‰ç‰¹è‰²ã€‚"""

        return prompt

    def extract_story_info(self, story_text: str) -> Tuple[str, str]:
        """æå–æ•…äº‹æ ‡é¢˜å’Œå†…å®¹"""
        lines = [x.strip() for x in story_text.split("\n") if x.strip()]

        if not lines:
            raise ValueError("æ•…äº‹å†…å®¹ä¸ºç©º")

        # æå–æ ‡é¢˜ï¼ˆå»é™¤å„ç§å¯èƒ½çš„æ ‡è®°ï¼‰
        title_line = lines[0]
        title = re.sub(r'^[ã€Šã€Œã€\*]*|[ã€‹ã€ã€‘\*]*$', '', title_line).strip()

        # æå–å†…å®¹ï¼ˆè·³è¿‡ç©ºè¡Œï¼‰
        content_lines = []
        for line in lines[1:]:
            if line:  # éç©ºè¡Œ
                content_lines.append(line)

        content = "\n".join(content_lines)

        if not title or not content:
            raise ValueError("æ ‡é¢˜æˆ–å†…å®¹æå–å¤±è´¥")

        return title, content

    def save_story(self, title: str, content: str) -> bool:
        """ä¿å­˜æ•…äº‹åˆ°æ–‡ä»¶"""
        try:
            filename = f"_posts/{datetime.now().strftime('%Y-%m-%d')}-{title}.md"

            with open(filename, "w", encoding='utf-8') as f:
                f.write(f"---\n")
                f.write(f"title: {title}\n")
                f.write(f"date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S +0800')}\n")
                f.write(f"---\n")
                f.write(f"\n")
                f.write(f"{content}\n")

            print(f"âœ… æˆåŠŸä¿å­˜æ•…äº‹: {title}")
            return True

        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return False

    def generate_story(self, max_attempts: int = 5) -> bool:
        """ç”Ÿæˆæ•…äº‹çš„ä¸»å‡½æ•°"""
        existing_titles = self.load_existing_titles()

        headers = {
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json"
        }

        for attempt in range(1, max_attempts + 1):
            print(f"\nğŸ”„ ç¬¬ {attempt} æ¬¡å°è¯•ç”Ÿæˆæ•…äº‹...")

            # ç”Ÿæˆæç¤ºè¯
            prompt = self.generate_enhanced_prompt(existing_titles, attempt)

            # APIè°ƒç”¨å‚æ•°
            data = {
                "model": "deepseek-chat",
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½æ‰åæ¨ªæº¢çš„é­”å¹»ç°å®ä¸»ä¹‰ä½œå®¶ï¼Œæ“…é•¿åˆ›ä½œç‹¬ç‰¹è€Œå¯Œæœ‰è¯—æ„çš„ä½œå“ã€‚ä½ ä»ä¸é‡å¤ä½¿ç”¨ç›¸åŒçš„æ ‡é¢˜æ¨¡å¼ï¼Œæ¯ä¸ªæ•…äº‹éƒ½æœ‰ç‹¬ç‰¹çš„æ ‡é¢˜å’Œæ·±åˆ»çš„å†…æ¶µã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": 0.7 + (attempt - 1) * 0.1,  # éšå°è¯•æ¬¡æ•°å¢åŠ åˆ›é€ æ€§
                "max_tokens": 2000,
                "top_p": 0.9
            }

            try:
                # è°ƒç”¨API
                response = requests.post(API_URL, json=data, headers=headers)
                result = response.json()

                if "choices" not in result:
                    print(f"âŒ APIè°ƒç”¨å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    continue

                story_text = result["choices"][0]["message"]["content"]
                print(f"ğŸ“ ç”Ÿæˆçš„æ•…äº‹å†…å®¹é¢„è§ˆ:\n{story_text[:200]}...")

                # æå–æ ‡é¢˜å’Œå†…å®¹
                title, content = self.extract_story_info(story_text)
                print(f"ğŸ“‘ æå–çš„æ ‡é¢˜: {title}")

                # æ£€æŸ¥æ ‡é¢˜è´¨é‡
                is_acceptable, reason = self.analyzer.is_title_acceptable(title, existing_titles)

                if is_acceptable:
                    # ä¿å­˜æ•…äº‹
                    if self.save_story(title, content):
                        print(f"ğŸ‰ æˆåŠŸï¼{reason}")
                        return True
                else:
                    print(f"âŒ æ ‡é¢˜ä¸åˆæ ¼: {reason}")
                    if attempt < max_attempts:
                        print(f"ğŸ”„ å‡†å¤‡ç¬¬ {attempt + 1} æ¬¡å°è¯•...")

            except Exception as e:
                print(f"âŒ å¤„ç†è¿‡ç¨‹å‡ºé”™: {e}")
                continue

        print(f"ğŸ’¥ ç»è¿‡ {max_attempts} æ¬¡å°è¯•ä»æœªæˆåŠŸç”Ÿæˆåˆæ ¼çš„æ•…äº‹")
        return False


def main():
    """ä¸»å‡½æ•°"""
    if not API_KEY:
        print("âŒ é”™è¯¯: è¯·è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
        return

    # ç¡®ä¿_postsç›®å½•å­˜åœ¨
    os.makedirs("_posts", exist_ok=True)

    generator = SmartStoryGenerator()
    success = generator.generate_story(max_attempts=5)

    if not success:
        exit(1)


if __name__ == "__main__":
    main()